# Papers I read
I can't guarantee correctness of my short notes for each paper. But if you find me misunderstand some of these papers, welcome to contact me and share your thoughts. :)

Topics:    
[General NLP](#General-NLP)   
[Explainable Model](#-Explainable-Model-in-NLP)    
[Adversarial](#-Adversarial-Training)             
[Style Transfer](#-Style-Transfer)     
[Counterfactual](#Counterfactual-Generation)                 

Links:    
[Hugging Face Transformer](https://huggingface.co/)


## General NLP

[**(2020) Experience Grounds Language**](https://arxiv.org/abs/2004.10151)      
A general review of how NLP will develop in future.  

## Explainable Model in NLP (Post-hoc)

[**(2017) Understanding Neural Networks through Representation Erasure**](https://arxiv.org/abs/1612.08220)      
Explain nerual network with word importance.

[**(2018) Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs**](https://arxiv.org/abs/1801.05453)-[Code](https://github.com/jamie-murdoch/ContextualDecomposition)    
Contextual Decomposition algorithm.

[**(2019) Interpretable machine learning: definitions, methods, and applications**](https://arxiv.org/abs/1901.04592)     
A framework for interpretability.

[**(2019) Hierarchical interpretations for neural network predictions**](https://arxiv.org/abs/1806.05337)-[Code](https://github.com/csinva/hierarchical-dnn-interpretations)      
Update on CD algorithm, purposed ACD, can interpret phrase level.

[**(2019) Disentangled Attribution Curves for Interpreting Random Forests and Boosted Trees**](https://arxiv.org/abs/1905.07631)-[Code](https://github.com/csinva/disentangled-attribution-curves)      
Disentangled Attribution Curves (DAC), a method to provide interpretations of tree ensemble methods. 

[**(2019) Interpretations are useful: penalizing explanations to align neural networks with prior knowledge**](https://arxiv.org/abs/1909.13584)-[Code](https://github.com/laura-rieger/deep-explanation-penalization)      
contextual decomposition explanation penalization, hummm like adversarial attack?

[**(2020) Towards Hierarchical Importance Attribution: Explaining Compositional Semantics for Neural Sequence Models**](https://arxiv.org/abs/1911.06194)-[Code](https://github.com/INK-USC/hierarchical-explanation-neural-sequence-models)      
Update on ACD, proposed SCD and SOC.

## Adversarial Training

[**(2018) Towards Deep Learning Models Resistant to Adversarial Attacks**](https://arxiv.org/abs/1706.06083)     
Adversarial attack algorithm FGSM and PGD.

## Style Transfer

[**(2019) Mask and Infill: Applying Masked Language Model to Sentiment Transfer**](https://arxiv.org/abs/1908.08039)      
Use Mask and Infill replace sentiment words to do style transfer.

## Counterfactual Generation

[**(2020) Learning the Difference that Makes a Difference with Counterfactually-Augmented Data**](https://arxiv.org/abs/1909.12434)-[Data](https://github.com/acmi-lab/counterfactually-augmented-data)     
Same as what title tells

## Other
